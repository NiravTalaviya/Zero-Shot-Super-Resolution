{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "video-zssr.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8fFGmjNOp9K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def super_resolution(img, sr_factor, model=None):\n",
        "    \"\"\"Super Resolve an image\n",
        "\n",
        "    Args:\n",
        "        img (numpy array): Input image\n",
        "        sr_factor (int): Factor by which resolution should increase\n",
        "        model (tf model): Trained ML model for SR\n",
        "    Returns:\n",
        "        sr_img (numpy array): Super Resolved image\n",
        "    \"\"\"\n",
        "    if model is None:\n",
        "        res = cv2.resize(img, None, fx=sr_factor, fy=sr_factor, interpolation=cv2.INTER_CUBIC)\n",
        "        return res\n",
        "    \n",
        "    img = img.astype(np.float32)\n",
        "    interpolated_image = cv2.resize(img, None, fx=sr_factor, fy=sr_factor, interpolation=cv2.INTER_CUBIC)  # Interpolation\n",
        "    interpolated_image = np.expand_dims(interpolated_image, axis=0) # Expand dims for NN\n",
        "    \n",
        "    sr_img = model.predict(interpolated_image)\n",
        "    sr_img = sr_img[0, :, :, :].astype(np.uint8)\n",
        "    sr_img = np.clip(sr_img, 0, 255)\n",
        "\n",
        "    return sr_img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DORSAZFTRSzr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SR_FACTOR = 2\n",
        "\n",
        " # Mean pixel noise added to lr sons\n",
        "INITIAL_LRATE = 0.001 # INITIAL Learning rat\n",
        "CV_IMWRITE_PNG_COMPRESSION = 9 # png compression ratio: best quality\n",
        "LEARNING_RATE_CYCLES = False # Decide if learning rate should drop in cyclic periods."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UABHW9i2H-u4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "375b9d29-f2fc-439e-ea86-abc9f9737f2c"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "name = 'letters'\n",
        "\n",
        "cap = cv2.VideoCapture('/content/' + name + '.mp4')\n",
        "if (cap.isOpened()== False): \n",
        "    print(\"Error opening video stream or file\")\n",
        "\n",
        "w = int(cap.get(3))\n",
        "h = int(cap.get(4))\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "frame_array=[]\n",
        "size = (w,h)\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, img = cap.read()\n",
        "    if ret == True:\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "        frame_array.append(img)\n",
        "    else:\n",
        "        break\n",
        "\n",
        "frame_array = np.array(frame_array)\n",
        "lr_array = frame_array.copy()\n",
        "frame_array.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(99, 320, 240, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3c3Nuf9g66e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6a7bbdc8-1aea-4223-f3b7-75db5e12c7b6"
      },
      "source": [
        "from data import DatasetLoader\n",
        "from utils import *\n",
        "from network import ZSSR\n",
        "\n",
        "import time\n",
        "import math\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "SR_FACTOR = 2 # scaling factor\n",
        "EPOCHS = 5000\n",
        "NB_PAIRS = math.ceil(EPOCHS / frame_array.shape[0])# NB pais \n",
        "NB_STEPS = 1 # Steps per epoch\n",
        "\n",
        "NB_CHANNELS = 3 #Channels\n",
        "FILTERS = 64 # FILTERS\n",
        "\n",
        "CROP_SIZE = [96] # image crop size\n",
        "NOISE_FLAG = True\n",
        "NOISY_PIXELS_STD = 0.04\n",
        "\n",
        "\n",
        "dl = DatasetLoader((frame_array.shape[1], frame_array.shape[2],\n",
        "                 frame_array.shape[3]),\n",
        "                )\n",
        "s_fact, inter_s_fact = dl.s_fact(SR_FACTOR, NB_PAIRS, NB_STEPS)\n",
        "\n",
        "\n",
        "zssr = ZSSR(NB_CHANNELS, FILTERS)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=INITIAL_LRATE)\n",
        "\n",
        "def loss(model, x, y, training):\n",
        "  y_ = model(x, training=training)\n",
        "  mse = tf.keras.losses.MeanSquaredError(reduction=tf.keras.losses.Reduction.SUM)\n",
        "  psnr = tf.image.psnr(y, y_, max_val = 255)\n",
        "  return mse(tf.reshape(y, [-1]), tf.reshape(y_, [-1])), psnr\n",
        "def grad(model, inputs, targets):\n",
        "  with tf.GradientTape() as tape:\n",
        "    loss_value, psnr_value = loss(model, inputs, targets, training=True)\n",
        "  return loss_value, psnr_value, tape.gradient(loss_value, model.trainable_variables)\n",
        "\n",
        "train_loss_avg = []\n",
        "train_psnr_avg = []\n",
        "\n",
        "st = time.time()\n",
        "for sf, isf in zip(s_fact, inter_s_fact):\n",
        "    for frame in frame_array:\n",
        "        X, y = preprocess(frame, sf, isf, CROP_SIZE,\n",
        "                          NOISE_FLAG, NOISY_PIXELS_STD)\n",
        "        ''' Train zssr '''\n",
        "        loss_value, psnr_value, grads = grad(zssr, X, y)\n",
        "        optimizer.apply_gradients(zip(grads, zssr.trainable_variables))\n",
        "\n",
        "et = time.time()\n",
        "print(\"Time spent: \", time_diff(et, st))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time spent:  (3, 33)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGuYrOwiyYge",
        "colab_type": "text"
      },
      "source": [
        "# Assemble Video"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jnZk1ih6qSC",
        "colab_type": "text"
      },
      "source": [
        "## ZSSR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmyWDAx_lezs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1e10824e-6abf-46d8-bc83-adcc7b9fe0f6"
      },
      "source": [
        "st = time.time()\n",
        "\n",
        "path_out = 'zssr_' + name + '_e' + str(EPOCHS) +'.avi'\n",
        "out_size = (lr_array[0].shape[1] * SR_FACTOR, lr_array[0].shape[0] * SR_FACTOR)\n",
        "out = cv2.VideoWriter(path_out, cv2.VideoWriter_fourcc(*'DIVX'), fps, out_size)\n",
        "\n",
        "for lr in lr_array:\n",
        "    sr = super_resolution(lr, SR_FACTOR, model=zssr)\n",
        "    sr = cv2.cvtColor(sr, cv2.COLOR_BGR2RGB)\n",
        "    out.write(sr)\n",
        "out.release()\n",
        "\n",
        "et = time.time()\n",
        "print(\"Save time spent: \", time_diff(et, st))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Save time spent:  (0, 16)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YmXVl1XQ6sCF",
        "colab_type": "text"
      },
      "source": [
        "## Bicubic"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlWauziEwqKG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e1a128d1-bad6-4156-a4f4-3137354d14c2"
      },
      "source": [
        "st = time.time()\n",
        "\n",
        "path_out = 'bicubic_' + name +'.avi'\n",
        "out_size = (lr_array[0].shape[1] * SR_FACTOR, lr_array[0].shape[0] * SR_FACTOR)\n",
        "out = cv2.VideoWriter(path_out, cv2.VideoWriter_fourcc(*'DIVX'), fps, out_size)\n",
        "\n",
        "for lr in lr_array:\n",
        "    sr = super_resolution(lr, SR_FACTOR)\n",
        "    sr = cv2.cvtColor(sr, cv2.COLOR_BGR2RGB)\n",
        "    out.write(sr)\n",
        "out.release()\n",
        "\n",
        "et = time.time()\n",
        "print(\"Save time spent: \", time_diff(et, st))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Save time spent:  (0, 0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KK3TN-mT65Al",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}