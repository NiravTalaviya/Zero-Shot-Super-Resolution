{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "zssr.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oHYbZ2Zmu1Z",
        "colab_type": "text"
      },
      "source": [
        "Python 3\n",
        "Tensorflow CPU version\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "457SIhP2SDJo",
        "outputId": "ec0333b3-05d8-4173-a89b-373aadc91f82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWLwSdhq_JNy",
        "colab_type": "code",
        "outputId": "46c8c438-97a5-4593-f2a6-b2a2237d176a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "try:\n",
        "    %tensorflow_version 2.x\n",
        "except:\n",
        "    pass\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Model, layers\n",
        "from tensorflow.keras.layers import Conv2D, UpSampling2D, LeakyReLU, Concatenate, BatchNormalization, MaxPool2D\n",
        "from tensorflow.keras.applications import DenseNet169, DenseNet121, densenet\n",
        "import tensorflow.keras.backend as K\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg \n",
        "from sklearn.utils import shuffle\n",
        "import keras\n",
        "from keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
        "import os\n",
        "from PIL import Image \n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
        "import glob\n",
        "import time\n",
        "from shutil import copy\n",
        "import cv2\n",
        "from time import strftime, localtime\n",
        "os.chdir('/content/drive/My Drive/ZSSR-master/')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yC7CMrex79p4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "start_time = time.time()\n",
        "SR_FACTOR = 2 # scaling factor\n",
        "BLUR_LOW = 0.4 # Scaling factors - blurring parameters\n",
        "BLUR_HIGH = 0.95 \n",
        "NB_CHANNELS = 3 #Channels\n",
        "FILTERS = 64 # FILTERS\n",
        "CROP_SIZE = [96] # image crop size\n",
        "NB_PAIRS = EPOCHS = 1500 # NB pais \n",
        "NB_STEPS = 1 # Steps per epoch\n",
        "NOISE_FLAG = False\n",
        "NOISY_PIXELS_STD = 30 # Mean pixel noise added to lr sons\n",
        "INITIAL_LRATE = 0.001 # INITIAL Learning rat\n",
        "CV_IMWRITE_PNG_COMPRESSION = 9 # png compression ratio: best quality\n",
        "LEARNING_RATE_CYCLES = False # Decide if learning rate should drop in cyclic periods."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7757IjmWF8r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_image(image):\n",
        "  plt.figure()\n",
        "  plt.imshow(image)\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "def predict_func(image):\n",
        "    image = image.astype(np.float32)\n",
        "    interpolated_image = cv2.resize(image, None, fx=SR_FACTOR, fy=SR_FACTOR, interpolation=cv2.INTER_CUBIC)  # Interpolation\n",
        "    interpolated_image = np.expand_dims(interpolated_image, axis=0) # Expand dims for NN\n",
        "    \n",
        "    super_image        = zssr.predict(interpolated_image)                  # prediction using model\n",
        "     \n",
        "    super_image        = np.squeeze(super_image, axis=(0))                 # reduction in dimention\n",
        "    interpolated_image = np.squeeze(interpolated_image, axis=(0))          # reduction in dimension\n",
        "\n",
        "    super_image        = cv2.convertScaleAbs(super_image)                  # Conversion to original datatype \n",
        "    interpolated_image = cv2.convertScaleAbs(interpolated_image)           # Conversion to original datatypa\n",
        "    image              = cv2.convertScaleAbs(image)                        # Conversion to original datatype\n",
        "    \n",
        "    # Save Original image\n",
        "    cv2.imwrite(result_path + '/' + str(SR_FACTOR) + '_origin.png', cv2.cvtColor(image, cv2.COLOR_RGB2BGR),\n",
        "                params=[CV_IMWRITE_PNG_COMPRESSION])\n",
        "    # Save super res image\n",
        "    cv2.imwrite(result_path + '/' + str(SR_FACTOR) + '_super.png', cv2.cvtColor(super_image, cv2.COLOR_RGB2BGR),\n",
        "                params=[CV_IMWRITE_PNG_COMPRESSION])\n",
        "    # Save bi-cubic enlarged image\n",
        "    cv2.imwrite(result_path + '/' + str(SR_FACTOR) + '_super_size_interpolated.png',\n",
        "                cv2.cvtColor(interpolated_image, cv2.COLOR_RGB2BGR), params=[CV_IMWRITE_PNG_COMPRESSION])\n",
        "    \n",
        "    return super_image, interpolated_image\n",
        "\n",
        "def accumulated_result(image):\n",
        "    image = image.astype(np.float32)\n",
        "    int_image = cv2.resize(image, None, fx=SR_FACTOR, fy=SR_FACTOR, interpolation=cv2.INTER_CUBIC)  # Interpolation\n",
        "    \n",
        "    print(\"NN Input shape:\", np.shape(int_image))\n",
        "    super_image_accumulated = np.zeros(np.shape(int_image))\n",
        "    \n",
        "    super_image_list = []\n",
        "    for k in range(0, 8):\n",
        "        print(\"Varient of image \", k)\n",
        "        img = np.rot90(int_image, k, axes=(0, 1))\n",
        "        if (k > 3):\n",
        "            img = np.fliplr(img)\n",
        "        # Expand dims for NN\n",
        "        img = np.expand_dims(img, axis=0)\n",
        "        super_img = zssr.predict(img)\n",
        "        super_img = np.squeeze(super_img, axis=(0))\n",
        "        super_img = cv2.convertScaleAbs(super_img)\n",
        "\n",
        "        if (k > 3):\n",
        "            super_img = np.fliplr(super_img)               # images should be UN-Rotated before added together\n",
        "        super_img = np.rot90(super_img, -k, axes=(0, 1))   # Unrotating      \n",
        "        super_image_list.append(super_img)\n",
        "        super_image_accumulated = super_image_accumulated + super_img\n",
        "\n",
        "    super_image_accumulated_avg = np.divide(super_image_accumulated, 8)                  # Taking mean \n",
        "    super_image_accumulated_avg = cv2.convertScaleAbs(super_image_accumulated_avg)       # Convert back to uint8\n",
        "\n",
        "    # Save accumulated avg result\n",
        "    cv2.imwrite(result_path + '/' + str(SR_FACTOR) + '_super_image_accumulated_avg.png',\n",
        "                cv2.cvtColor(super_image_accumulated_avg, cv2.COLOR_RGB2BGR), params=[CV_IMWRITE_PNG_COMPRESSION])\n",
        "\n",
        "    \n",
        "    super_image_accumulated_median = np.median(super_image_list, axis=0)                 # taking median\n",
        "    super_image_accumulated_median = cv2.convertScaleAbs(super_image_accumulated_median) #Convert back to uint8\n",
        "\n",
        "    # Save Accumulated median result\n",
        "    cv2.imwrite(result_path + '/' + str(SR_FACTOR) + '_super_image_accumulated_median.png',\n",
        "                cv2.cvtColor(super_image_accumulated_median, cv2.COLOR_RGB2BGR), params=[CV_IMWRITE_PNG_COMPRESSION])\n",
        "\n",
        "    return super_image_accumulated_median, super_image_accumulated_avg\n",
        "\n",
        "\n",
        "# They have used very fantastic approach\n",
        "def prepare_result_dir():\n",
        "    # Create results directory\n",
        "    path= strftime('_%b_%d_%H_%M_%S', localtime())\n",
        "    result_path = 'results/test'  + path\n",
        "    os.makedirs(result_path)\n",
        "    print(result_path)\n",
        "    for py_file in glob.glob('*.ipynb'):\n",
        "        copy(py_file, result_path)\n",
        "    return result_path\n",
        "\n",
        "def time_diff(end_time, start_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs\n",
        "    \n",
        "def step_decay(epochs):\n",
        "    initial_lrate = INITIAL_LRATE\n",
        "    drop = 0.5\n",
        "    if LEARNING_RATE_CYCLES:\n",
        "        cycle = np.ceil(NB_PAIRS / NB_SCALING_STEPS)\n",
        "        epochs_drop = np.ceil((NB_STEPS * EPOCHS) / NB_SCALING_STEPS)\n",
        "        step_length = int(epochs_drop / 5)\n",
        "    else:\n",
        "        cycle = NB_PAIRS\n",
        "        epochs_drop = np.ceil((NB_STEPS * EPOCHS) / 5)\n",
        "        step_length = epochs_drop\n",
        "\n",
        "    lrate = initial_lrate * np.power(drop, np.floor((1 + np.mod(epochs, cycle)) / step_length))\n",
        "    return lrate\n",
        "\n",
        "def add_noise(image):\n",
        "    row, col, ch = image.shape\n",
        "    noise = np.random.normal(0, NOISY_PIXELS_STD, (row, col, ch))\n",
        "    noise = noise.astype('float32')\n",
        "    noisy = np.clip((image + noise), 0, 255)\n",
        "    return noisy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pz7VBJE_ktNM",
        "colab_type": "text"
      },
      "source": [
        "### Image preproccessing step"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jMkDnfj-ZfO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "class DatasetLoader():\n",
        "    def __init__(self,ip_path = 'real_example/*.png'):\n",
        "        self.image_list = glob.glob(ip_path)[0]\n",
        "        self.image = self.load_img(self.image_list)\n",
        "        self.s_fact()\n",
        "        self.gt_image = None\n",
        "\n",
        "    def set_groundtruth(self, gt_path):\n",
        "        image = cv2.imread(gt_path)\n",
        "        self.gt_image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
        "        \n",
        "    def load_img(self, file_name):\n",
        "        image = cv2.imread(file_name)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
        "        plt.figure()\n",
        "        plt.imshow(image)\n",
        "        plt.show()\n",
        "        image = image.astype(np.float32)\n",
        "        return image\n",
        "\n",
        "    def s_fact(self, NB_PAIRS=1500, NB_SCALING_STEPS=1): # NB_PAIRS=1500, BATCH_SIZE = 1, NB_SCALING_STEPS = 1\n",
        "        image = self.image;\n",
        "        BLUR_LOW_BIAS = 0.0 \n",
        "        scale_factors = np.empty(0)\n",
        "        \n",
        "        lenpad = np.int(NB_PAIRS / NB_SCALING_STEPS)\n",
        "\n",
        "        if image.shape[0] * image.shape[1] <= 50 * 50:\n",
        "          BLUR_LOW_BIAS = 0.3\n",
        "        for i in range(NB_SCALING_STEPS):\n",
        "          temp = np.random.uniform(BLUR_LOW + BLUR_LOW_BIAS, BLUR_HIGH, lenpad)  # Low = 0.4, High = 0.95\n",
        "          temp = np.sort(temp)\n",
        "          scale_factors = np.append(scale_factors, temp, axis=0)\n",
        "          scale_factors = np.around(scale_factors, decimals=5)\n",
        "        \n",
        "        \"\"\"for adding pad when there is mismatch in size of scale_factor and NB_PAIRS \n",
        "        if NB_SCALING STEPS is 3 and NB_PAIRS is 1499 then scale_factor would be generated of only 1497\n",
        "        it has to be converted into 1499\"\"\"\n",
        "        scale_factors_pad = np.repeat(scale_factors[-1], abs(NB_PAIRS - len(scale_factors)))\n",
        "        scale_factors = np.concatenate((scale_factors, scale_factors_pad), axis=0)\n",
        "\n",
        "        # Intermediate SR_Factors\n",
        "        \"\"\"np.linspace(1,SR_FACTOR=2,(NB_SCALING_STEPS = 5) + 1) output would [1,1.2,1.4,1.6,1.8,2]\n",
        "        There is +1 because in the next step element at 0th index would be deleted \"\"\"\n",
        "        \n",
        "        intermidiate_SR_Factors = np.delete(np.linspace(1, SR_FACTOR, NB_SCALING_STEPS + 1), 0)\n",
        "        intermidiate_SR_Factors = np.around(intermidiate_SR_Factors, decimals=3)\n",
        "\n",
        "        # Now, size of intermidiate_SR_Factors is of NB_SCALING_STEPS\n",
        "        # we want to repeat it in such a way to its size becomes equal to the scale_factors and that is done by below three lines\n",
        "        intermidiate_SR_Factors = np.repeat(intermidiate_SR_Factors, lenpad) # repeat intermidiate_SR_Factors for lenpad\n",
        "        pad = np.repeat(intermidiate_SR_Factors[-1], abs(len(intermidiate_SR_Factors) - max(len(scale_factors), NB_PAIRS)))  #there could be mismatch as explained before so for padding this step is there\n",
        "        intermidiate_SR_Factors = np.concatenate((intermidiate_SR_Factors, pad), axis=0)\n",
        "        \n",
        "        self.scale_factors=scale_factors\n",
        "        self.intermidiate_SR_Factors = intermidiate_SR_Factors;\n",
        "\n",
        "        # print(\"sr factors: \", self.scale_factors)\n",
        "        # print(\"inter sr factors: \", self.intermidiate_SR_Factors)\n",
        "        \n",
        "        return self.scale_factors, self.intermidiate_SR_Factors\n",
        "\n",
        "    def preprocess(self, scale_fact, scale_fact_inter):\n",
        "        # scale down is sthe inverse of the intermediate scaling factor\n",
        "        scale_down = 1 / scale_fact_inter \n",
        "        \n",
        "        # Create hr father by downscaling from the original image\n",
        "        hr = cv2.resize(self.image, None, fx=scale_fact, fy=scale_fact, interpolation=cv2.INTER_CUBIC)\n",
        "        \n",
        "        # Crop the HR father to reduce computation cost and set the training independent from image size\n",
        "        h_crop = w_crop = np.random.choice(CROP_SIZE)\n",
        "        if (hr.shape[0] > h_crop):\n",
        "            x0 = np.random.randint(0, hr.shape[0] - h_crop)\n",
        "            h = h_crop\n",
        "        else:\n",
        "            x0 = 0\n",
        "            h = hr.shape[0]\n",
        "        if (hr.shape[1] > w_crop):\n",
        "            x1 = np.random.randint(0, hr.shape[1] - w_crop)\n",
        "            w = w_crop\n",
        "        else:\n",
        "            x1 = 0\n",
        "            w = hr.shape[1]\n",
        "        hr = hr[x0 : x0 + h, x1 : x1 + w]\n",
        "            \n",
        "        k = np.random.choice(8)\n",
        "        hr = np.rot90(hr, k, axes=(0, 1))\n",
        "        if (k > 3):\n",
        "            hr = np.fliplr(hr)\n",
        "        \n",
        "        # hr is cropped and flipped then copies as lr\n",
        "        # Blur lr son\n",
        "        lr = cv2.resize(hr, None, fx=scale_down, fy=scale_down, interpolation=cv2.INTER_CUBIC)\n",
        "        # Upsample lr to the same size as hr\n",
        "        lr = cv2.resize(lr, (hr.shape[1], hr.shape[0]), interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "        if NOISE_FLAG:         # noise addition\n",
        "            lr = add_noise(lr)\n",
        "\n",
        "        lr = np.expand_dims(lr, axis=0)  # Expanding dimension\n",
        "        hr = np.expand_dims(hr, axis=0)  # Expanding dimension\n",
        "        X = lr\n",
        "        y = hr\n",
        "        return X, y\n",
        "\n",
        "    def image_generator(self):\n",
        "      i = 0\n",
        "      scale_fact, scale_fact_inter = self.s_fact()\n",
        "      while True:\n",
        "        print(size(scale_fact))\n",
        "        X, y = self.preprocess(scale_fact[i] + np.round(np.random.normal(0.0, 0.03), decimals=3), scale_fact_inter[i])\n",
        "        i = i + 1\n",
        "        yield X, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0e3gLTusc5K",
        "colab_type": "text"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ahb-AF0lsa8Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "6f2226a4-7809-4f3b-825e-2471452bbbea"
      },
      "source": [
        "class ZSSR(Model):\n",
        "  def __init__(self):\n",
        "    super(ZSSR, self).__init__()\n",
        "    ALPHA = 0.2\n",
        "    self.convA = Conv2D(filters=NB_CHANNELS, kernel_size=(3, 3), strides = 1, padding='same')\n",
        "    self.reluA = LeakyReLU(alpha=ALPHA)  \n",
        "    # inner layer 1\n",
        "    self.conv2d_i_1 = Conv2D(filters=FILTERS, kernel_size=(3,3), strides=1, padding='same')\n",
        "    self.relu_i_1 = LeakyReLU(alpha=ALPHA)\n",
        "    # inner layer 2\n",
        "    self.conv2d_i_2 = Conv2D(filters=FILTERS, kernel_size=(3,3), strides=1, padding='same')\n",
        "    self.relu_i_2 = LeakyReLU(alpha=ALPHA)\n",
        "    # inner layer 3\n",
        "    self.conv2d_i_3 = Conv2D(filters=FILTERS, kernel_size=(3,3), strides=1, padding='same')\n",
        "    self.relu_i_3 = LeakyReLU(alpha=ALPHA)\n",
        "    # inner layer 4\n",
        "    self.conv2d_i_4 = Conv2D(filters=FILTERS, kernel_size=(3,3), strides=1, padding='same')\n",
        "    self.relu_i_4 = LeakyReLU(alpha=ALPHA)\n",
        "    # inner layer 5\n",
        "    self.conv2d_i_5 = Conv2D(filters=FILTERS, kernel_size=(3,3), strides=1, padding='same')\n",
        "    self.relu_i_5 = LeakyReLU(alpha=ALPHA)\n",
        "    # inner layer 6\n",
        "    self.conv2d_i_6 = Conv2D(filters=FILTERS, kernel_size=(3,3), strides=1, padding='same')\n",
        "    self.relu_i_6 = LeakyReLU(alpha=ALPHA)\n",
        "    # inner layer 7\n",
        "    self.conv2d_i_7 = Conv2D(filters=FILTERS, kernel_size=(3,3), strides=1, padding='same')\n",
        "    self.relu_i_7 = LeakyReLU(alpha=ALPHA)\n",
        "    # inner layer 7\n",
        "    self.conv2d_i_8 = Conv2D(filters=FILTERS, kernel_size=(3,3), strides=1, padding='same')\n",
        "    self.relu_i_8 = LeakyReLU(alpha=ALPHA)\n",
        "\n",
        "    self.convB = Conv2D(filters=NB_CHANNELS, kernel_size=(3,3), strides=1, padding='same', activation='linear')\n",
        "  \n",
        "  def call(self, inputs):\n",
        "    x = self.convA(inputs)\n",
        "    x = self.reluA(x)\n",
        "\n",
        "    x = self.conv2d_i_1(x)\n",
        "    x = self.relu_i_1(x)\n",
        "    \n",
        "    x = self.conv2d_i_2(x)\n",
        "    x = self.relu_i_2(x)\n",
        "\n",
        "    x = self.conv2d_i_3(x)\n",
        "    x = self.relu_i_3(x)\n",
        "    \n",
        "    x = self.conv2d_i_4(x)\n",
        "    x = self.relu_i_4(x)\n",
        "\n",
        "    x = self.conv2d_i_5(x)\n",
        "    x = self.relu_i_5(x)\n",
        "    \n",
        "    x = self.conv2d_i_6(x)\n",
        "    x = self.relu_i_6(x)\n",
        "\n",
        "    x = self.conv2d_i_7(x)\n",
        "    x = self.relu_i_7(x)\n",
        "    \n",
        "    x = self.conv2d_i_8(x)\n",
        "    x = self.relu_i_8(x)\n",
        "\n",
        "    x = self.convB(x)\n",
        "    x = tf.keras.layers.add([x, inputs])\n",
        "    return x;\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-8ef15bd1721e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mZSSR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZSSR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mALPHA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNB_CHANNELS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beURJfIy6QrY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# monarch.png  I_2\n",
        "x_path = '../super-resolution/data/Set14/lr_2/I_2.jpg'\n",
        "y_path = '../super-resolution/data/Set14/hr/monarch.png'\n",
        "dl = DatasetLoader(x_path)\n",
        "dl.set_groundtruth(y_path)\n",
        "# dl = DatasetLoader()\n",
        "dataset_gen = dl.image_generator()\n",
        "\n",
        "# result_path = prepare_result_dir()\n",
        "zssr =ZSSR()\n",
        "zssr.compile(loss='mae', optimizer='adam', metrics=['accuracy'])\n",
        "callback = tf.keras.callbacks.LearningRateScheduler(step_decay)\n",
        "history = zssr.fit_generator(dataset_gen,\n",
        "                                 steps_per_epoch=NB_STEPS, \n",
        "                                 epochs=EPOCHS, \n",
        "                                 shuffle=False, \n",
        "                                callbacks=[callback],\n",
        "                                 max_queue_size=32,\n",
        "                                 verbose=0)\n",
        "\n",
        "# zssr.summary()\n",
        "super_image, interpolated_image = predict_func(dl.image)\n",
        "super_image_accumulated_median, super_image_accumulated_avg = accumulated_result(dl.image)\n",
        "print('  Bicubic '+ str(psnr(interpolated_image, super_image_accumulated_avg)))\n",
        "if dl.gt_image is None:\n",
        "  print('  Bicubic '+ str(psnr(interpolated_image,dl.gt_image)))\n",
        "  print('Predicted '+ str(psnr(super_image,dl.gt_image)))\n",
        "  print('   Median '+ str(psnr(super_image_accumulated_median,dl.gt_image)))\n",
        "  print('      Avg '+ str(psnr(super_image_accumulated_avg,dl.gt_image)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKq7AfjY-ZVA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = 0\n",
        "b = 500\n",
        "c = 0\n",
        "d = 200\n",
        "# from skimage.measure import compare_psnr\n",
        "col = 5\n",
        "if dl.gt_image is None:\n",
        "  col = col - 1\n",
        "(fig, axes) = plt.subplots(nrows=1, ncols=col, figsize=(25,25))\n",
        "axes[0].imshow(cv2.convertScaleAbs(dl.image[a:b,c:d]))\n",
        "axes[0].set_title('Original Image')\n",
        "axes[1].imshow(interpolated_image[a*2:b*2,c*2:d*2])\n",
        "axes[1].set_title('Bi Cubic Interpolation')\n",
        "axes[2].imshow(super_image[a*2:b*2,c*2:d*2])\n",
        "axes[2].set_title('Super Resolved Image')\n",
        "axes[3].imshow(super_image_accumulated_avg[a*2:b*2,c*2:d*2])\n",
        "axes[3].set_title('Mean')\n",
        "if dl.gt_image is not None:\n",
        "  axes[4].imshow(dl.gt_image[a*2:b*2,c*2:d*2])\n",
        "  axes[4].set_title('Ground Truth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfWK0unQu26L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "end_time = time.time()\n",
        "print(time_diff(end_time, start_time))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9j6RXaVNqd5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHRY6P1INqbI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzC2xS2bNqYu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtRLCOllNqWO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itMCx95uNqTf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSr4ZivSNqO7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wwiSlK7NqKx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZjoPxmcNqGM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BodsbVtq_Deo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Activation layer\n",
        "ACTIVATION = 'relu'\n",
        "# Data generator random ordered\n",
        "SHUFFLE = False\n",
        "# scaling factors array order random or sorted\n",
        "SORT = True\n",
        "# Ascending or Descending: 'A' or 'D'\n",
        "SORT_ORDER = 'A'\n",
        "# number of time steps (pairs) per epoch\n",
        "NB_STEPS = 1\n",
        "# kernel size\n",
        "KERNEL_SIZE = 3\n",
        "# Batch size\n",
        "BATCH_SIZE = 1\n",
        "# Number of channels in signal\n",
        "NB_CHANNELS = 3\n",
        "# No. of NN filters per layer\n",
        "FILTERS = 64  # 64 on the paper\n",
        "# Number of internal convolutional layers\n",
        "LAYERS_NUM = 6\n",
        "# No. of scaling steps. 6 is best value from paper.\n",
        "NB_SCALING_STEPS = 1\n",
        "# No. of LR_HR pairs\n",
        "EPOCHS = NB_PAIRS = 1500\n",
        "# Default crop size (in the paper: 128*128*3)\n",
        "CROP_SIZE = [96]#[32,64,96,128]\n",
        "# Momentum # default is 0.9 # 0.86 seems to give lowest loss *tested from 0.85-0.95\n",
        "BETA1 = 0.90  # 0.86\n",
        "# Adaptive learning rate\n",
        "INITIAL_LRATE = 0.001\n",
        "DROP = 0.5\n",
        "# Adaptive lrate, Number of learning rate steps (as in paper)\n",
        "FIVE = 5\n",
        "# Decide if learning rate should drop in cyclic periods.\n",
        "LEARNING_RATE_CYCLES = False\n",
        "#\n",
        "# EPOCHS_DROP = np.ceil((NB_STEPS * EPOCHS ) / NB_SCALING_STEPS)\n",
        "# Plot super resolution image when using zssr.predict\n",
        "PLOT_FLAG = False\n",
        "# Crop image for training\n",
        "CROP_FLAG = True\n",
        "# Flip flag\n",
        "FLIP_FLAG = True\n",
        "# initial scaling bias (org to fathers)\n",
        "SCALING_BIAS = 1\n",
        "# Add noise or not to transformations\n",
        "NOISE_FLAG = False\n",
        "# Mean pixel noise added to lr sons\n",
        "NOISY_PIXELS_STD = 30\n",
        "# Save augmentations\n",
        "SAVE_AUG = True\n",
        "# If there's a ground truth image. Add to parse.\n",
        "GROUND_TRUTH = True\n",
        "# If there's a baseline image. Add to parse.\n",
        "BASELINE = True\n",
        "# png compression ratio: best quality\n",
        "CV_IMWRITE_PNG_COMPRESSION = 9\n",
        "\n",
        "ORIGIN_IMAGE = 0\n",
        "GROUND_TRUTH_IMAGE = 1\n",
        "BASELINE_IMAGE = 2\n",
        "\n",
        "# We're making sure These parameters are equal, in case of an update from the parser.\n",
        "NB_PAIRS = EPOCHS\n",
        "EPOCHS_DROP = np.ceil((NB_STEPS * EPOCHS) / NB_SCALING_STEPS)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}